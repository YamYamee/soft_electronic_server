import numpy as np
import logging
from typing import List, Tuple, Dict, Any, Optional
import os
import random
import joblib
from datetime import datetime
from config import config
from database import PostureDatabase

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class EnsemblePosturePredictor:
    def __init__(self, model_path=None):
        self.model_path = model_path or config.MODEL_PATH
        self.models = {}  # 1ì°¨ ëª¨ë¸ë“¤ (FSR ê¸°ë°˜)
        self.models_stage2 = {}  # 2ì°¨ ëª¨ë¸ë“¤ (IMU ê¸°ë°˜)
        self.scaler = None  # 1ì°¨ ìŠ¤ì¼€ì¼ëŸ¬ (FSRìš©)
        self.scaler_stage2 = None  # 2ì°¨ ìŠ¤ì¼€ì¼ëŸ¬ (IMUìš©)
        self.posture_labels = {
            0: "ë°”ë¥¸ ìì„¸",
            1: "ê±°ë¶ëª© ìì„¸",
            2: "ëª© ìˆ™ì´ê¸°", 
            3: "ì•ìœ¼ë¡œ ë‹¹ê²¨ ê¸°ëŒ€ê¸°",
            4: "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°",
            5: "ì™¼ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°",
            6: "ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¼¬ê¸°",
            7: "ì™¼ìª½ ë‹¤ë¦¬ ê¼¬ê¸°"
        }
        self.supports_proba = True
        # Database manager for logging
        self.db_manager = PostureDatabase()
        self.load_ensemble_models()
        self.load_stage2_models()  # 2ì°¨ ëª¨ë¸ë“¤ ë¡œë“œ
        
        # ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ (ì„±ëŠ¥ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
        self.model_weights = {
            'lr': 0.3,    # Logistic Regression
            'rf': 0.35,   # Random Forest (ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì¢‹ìŒ)
            'dt': 0.2,    # Decision Tree
            'kn': 0.15    # K-Nearest Neighbors
        }
        
        # ì˜ˆì¸¡ ë¡œê·¸ë¥¼ ìœ„í•œ DB í…Œì´ë¸” ìƒì„±
        self.create_prediction_log_table()

    def load_stage2_models(self):
        """2ì°¨ ë¶„ë¥˜ìš© IMU ê¸°ë°˜ ëª¨ë¸ë“¤ ë¡œë“œ"""
        from logger_config import log_model_loading, log_model_loaded, log_ensemble_summary
        
        ml_dir = os.path.join(os.path.dirname(__file__), 'ML')
        stage2_model_files = {
            'lr2': 'model_lr2.joblib',
            'rf2': 'model_rf2.joblib', 
            'dt2': 'model_dt2.joblib',
            'kn2': 'model_kn2.joblib'
        }
        
        scaler2_path = os.path.join(ml_dir, 'scaler2.joblib')
        
        logger.info("=== 2ì°¨ ë¶„ë¥˜ ëª¨ë¸ ë¡œë”© ì‹œì‘ ===")
        
        # 2ì°¨ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        try:
            if os.path.exists(scaler2_path):
                self.scaler_stage2 = joblib.load(scaler2_path)
                logger.info("âœ… 2ì°¨ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì„±ê³µ")
            else:
                logger.warning("âš ï¸ 2ì°¨ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"âŒ 2ì°¨ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 2ì°¨ ëª¨ë¸ë“¤ ë¡œë“œ
        loaded_stage2_models = []
        for model_name, filename in stage2_model_files.items():
            model_path = os.path.join(ml_dir, filename)
            try:
                if os.path.exists(model_path):
                    model = joblib.load(model_path)
                    self.models_stage2[model_name] = model
                    loaded_stage2_models.append(model_name.upper())
                    logger.info(f"âœ… {model_name.upper()} 2ì°¨ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                else:
                    logger.warning(f"âš ï¸ {model_name.upper()} 2ì°¨ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {filename}")
            except Exception as e:
                logger.error(f"âŒ {model_name.upper()} 2ì°¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        if self.models_stage2:
            logger.info(f"ğŸ¯ 2ì°¨ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {loaded_stage2_models}")
        else:
            logger.warning("âš ï¸ 2ì°¨ ë¶„ë¥˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. IMU ê¸°ë°˜ ì„¸ë¶€ ë¶„ë¥˜ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    def create_prediction_log_table(self):
        """ì˜ˆì¸¡ ë¡œê·¸ë¥¼ ì €ì¥í•  í…Œì´ë¸” ìƒì„±"""
        try:
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS prediction_logs (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                        client_id TEXT,
                        device_id TEXT,
                        fsr_data TEXT NOT NULL,
                        imu_data TEXT,
                        raw_fsr_values TEXT,
                        preprocessed_data TEXT,
                        
                        -- ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼
                        lr_prediction INTEGER,
                        lr_confidence REAL,
                        rf_prediction INTEGER,
                        rf_confidence REAL,
                        dt_prediction INTEGER,
                        dt_confidence REAL,
                        kn_prediction INTEGER,
                        kn_confidence REAL,
                        
                        -- ì•™ìƒë¸” ê²°ê³¼
                        ensemble_prediction INTEGER NOT NULL,
                        ensemble_confidence REAL NOT NULL,
                        voting_scores TEXT,
                        
                        -- ë©”íƒ€ ì •ë³´
                        models_used TEXT,
                        prediction_method TEXT DEFAULT 'ensemble',
                        processing_time_ms REAL
                    )
                ''')
                conn.commit()
                logger.info("ì˜ˆì¸¡ ë¡œê·¸ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ë¡œê·¸ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    def load_ensemble_models(self):
        """ì—¬ëŸ¬ ML ëª¨ë¸ë“¤ì„ ë¡œë“œí•˜ì—¬ ì•™ìƒë¸” êµ¬ì„±"""
        from logger_config import log_model_loading, log_model_loaded, log_ensemble_summary
        
        ml_dir = os.path.join(os.path.dirname(__file__), 'ML')
        model_files = {
            'lr': 'model_lr.joblib',
            'rf': 'model_rf.joblib', 
            'dt': 'model_dt.joblib',
            'kn': 'model_kn.joblib'
        }
        
        scaler_path = os.path.join(ml_dir, 'scaler.joblib')
        
        log_model_loading()
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        try:
            if os.path.exists(scaler_path):
                self.scaler = joblib.load(scaler_path)
                log_model_loaded("Scaler", True)
            else:
                logger.warning("âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                log_model_loaded("Scaler", False)
        except Exception as e:
            logger.error(f"ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì˜¤ë¥˜: {e}")
            log_model_loaded("Scaler", False)
        
        # ê° ëª¨ë¸ ë¡œë“œ
        loaded_models = 0
        total_models = len(model_files)
        
        for model_name, model_file in model_files.items():
            model_path = os.path.join(ml_dir, model_file)
            try:
                if os.path.exists(model_path):
                    model = joblib.load(model_path)
                    self.models[model_name] = model
                    loaded_models += 1
                    log_model_loaded(model_name, True)
                else:
                    logger.warning(f"âš ï¸ {model_name.upper()} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                    log_model_loaded(model_name, False)
            except Exception as e:
                logger.error(f"âŒ {model_name.upper()} ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
                log_model_loaded(model_name, False)
        
        # ì•™ìƒë¸” êµ¬ì„± ì™„ë£Œ ë¡œê·¸
        log_ensemble_summary(loaded_models, total_models)
        
        if loaded_models == 0:
            logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ML ëª¨ë¸ì´ ì—†ì–´ ê·œì¹™ ê¸°ë°˜ ëª¨ë¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            self.create_simple_rule_based_model()
            
        return loaded_models > 0

    def create_simple_rule_based_model(self):
        """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ëª¨ë¸ ìƒì„± (ML ëª¨ë¸ ë¡œë“œê°€ ì‹¤íŒ¨í•  ê²½ìš° ì‚¬ìš©)"""
        logger.info("ê·œì¹™ ê¸°ë°˜ ìì„¸ ë¶„ë¥˜ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤")
        
        # FSR íŒ¨í„´ ê¸°ë°˜ ë¶„ë¥˜ ê·œì¹™
        self.classification_rules = {
            # ê° ìì„¸ë³„ FSR ì„¼ì„œ íŒ¨í„´ íŠ¹ì§•
            0: {'name': 'ë°”ë¥¸ ìì„¸', 'pattern': 'balanced'},
            1: {'name': 'ê±°ë¶ëª© ìì„¸', 'pattern': 'neck_forward'},
            2: {'name': 'ëª© ìˆ™ì´ê¸°', 'pattern': 'head_down'},
            3: {'name': 'ì•ìœ¼ë¡œ ë‹¹ê²¨ ê¸°ëŒ€ê¸°', 'pattern': 'front_heavy'},
            4: {'name': 'ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°', 'pattern': 'right_lean'},
            5: {'name': 'ì™¼ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°', 'pattern': 'left_lean'},
            6: {'name': 'ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¼¬ê¸°', 'pattern': 'right_leg_cross'},
            7: {'name': 'ì™¼ìª½ ë‹¤ë¦¬ ê¼¬ê¸°', 'pattern': 'left_leg_cross'}
        }
        
        self.models = {"rule_based": "rule_based"}
        logger.info("ê·œì¹™ ê¸°ë°˜ ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    
    def preprocess_data(self, fsr_data: np.ndarray) -> np.ndarray:
        """ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬"""
        from logger_config import log_data_preprocessing
        
        try:
            # FSR ë°ì´í„° ê²€ì¦
            if not isinstance(fsr_data, list):
                raise ValueError("FSR ë°ì´í„°ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤")
            
            # FSR ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            fsr_array = np.array(fsr_data, dtype=float)
            
            # ë°ì´í„° í¬ê¸° í™•ì¸ (11ê°œ ì„¼ì„œ ì˜ˆìƒ)
            expected_fsr_size = 11
            if len(fsr_array) != expected_fsr_size:
                logger.warning(f"ì˜ˆìƒ FSR ì„¼ì„œ ê°œìˆ˜ì™€ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: {expected_fsr_size}, ì‹¤ì œ: {len(fsr_array)}")
                # ë¶€ì¡±í•œ ê²½ìš° 0ìœ¼ë¡œ íŒ¨ë”©, ë§ì€ ê²½ìš° ìë¥´ê¸°
                if len(fsr_array) < expected_fsr_size:
                    fsr_array = np.pad(fsr_array, (0, expected_fsr_size - len(fsr_array)), mode='constant')
                else:
                    fsr_array = fsr_array[:expected_fsr_size]
            
            # FSR íŠ¹ì„±ë§Œ ì‚¬ìš© (IMUëŠ” ë³„ë„ í›„ì²˜ë¦¬ì—ì„œ í™œìš©)
            features = fsr_array
            logger.debug(f"FSR íŠ¹ì„±: {len(features)}ê°œ")
            
            # ìƒì„¸ ì „ì²˜ë¦¬ ë¡œê·¸ (DEBUG ë ˆë²¨)
            log_data_preprocessing(fsr_data, features, scaler_used=self.scaler is not None)
            
            return features
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            raise
    
    def preprocess_imu_data(self, imu_data) -> np.ndarray:
        """2ì°¨ ë¶„ë¥˜ìš© IMU ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            if not imu_data:
                logger.warning("IMU ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return np.zeros(6)  # ê¸°ë³¸ê°’: accel_x,y,z + gyro_x,y,z
            
            # IMU ë°ì´í„°ì—ì„œ íŠ¹ì„± ì¶”ì¶œ (í° í˜•ì‹: accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z)
            if isinstance(imu_data, dict):
                accel_x = float(imu_data.get('accel_x', 0.0))
                accel_y = float(imu_data.get('accel_y', 0.0))
                accel_z = float(imu_data.get('accel_z', 0.0))
                gyro_x = float(imu_data.get('gyro_x', 0.0))
                gyro_y = float(imu_data.get('gyro_y', 0.0))
                gyro_z = float(imu_data.get('gyro_z', 0.0))
                
                features = np.array([accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z], dtype=np.float32)
                logger.debug(f"IMU íŠ¹ì„± ì¶”ì¶œ: accel({accel_x:.2f}, {accel_y:.2f}, {accel_z:.2f}), gyro({gyro_x:.2f}, {gyro_y:.2f}, {gyro_z:.2f})")
                
            elif isinstance(imu_data, (list, tuple)) and len(imu_data) >= 6:
                features = np.array(imu_data[:6], dtype=np.float32)
                logger.debug(f"IMU ë°°ì—´ ë°ì´í„° ì‚¬ìš©: {features}")
                
            else:
                logger.warning(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ IMU ë°ì´í„° í˜•ì‹: {type(imu_data)}")
                return np.zeros(6)
            
            return features
            
        except Exception as e:
            logger.error(f"IMU ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return np.zeros(6)

    def analyze_fsr_pattern(self, fsr_data: np.ndarray) -> Tuple[int, float]:
        """FSR ë°ì´í„° íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ìì„¸ ë¶„ë¥˜"""
        try:
            # ì „ì²´ ì••ë ¥ í•©ê³„
            total_pressure = np.sum(fsr_data)
            
            if total_pressure == 0:
                return 0, 0.5  # ì••ë ¥ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ìì„¸
            
            # ê° ì„¼ì„œë³„ ë¹„ìœ¨ ê³„ì‚°
            ratios = fsr_data / total_pressure
            
            # ì¢Œìš° ê· í˜• ë¶„ì„ (ì„¼ì„œ 1-5: ì™¼ìª½, ì„¼ì„œ 6-11: ì˜¤ë¥¸ìª½ ê°€ì •)
            left_pressure = np.sum(fsr_data[:5])
            right_pressure = np.sum(fsr_data[5:])
            
            # ì•ë’¤ ê· í˜• ë¶„ì„ (ì„¼ì„œ ë°°ì¹˜ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            front_pressure = np.sum(fsr_data[[0, 1, 5, 6]])  # ì•ìª½ ì„¼ì„œë“¤
            back_pressure = np.sum(fsr_data[[3, 4, 8, 9]])   # ë’¤ìª½ ì„¼ì„œë“¤
            
            # ë¶„ë¥˜ ë¡œì§ (ìƒˆë¡œìš´ ìì„¸ ë¶„ë¥˜ì— ë§ê²Œ ì¡°ì •)
            if left_pressure > right_pressure * 1.5:
                # ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨
                if front_pressure > back_pressure:
                    predicted_posture = 7  # ì™¼ìª½ ë‹¤ë¦¬ ê¼­ê¸°
                else:
                    predicted_posture = 5  # ì™¼ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°
                confidence = min(0.9, (left_pressure / right_pressure - 1) * 0.5 + 0.6)
                
            elif right_pressure > left_pressure * 1.5:
                # ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨
                if front_pressure > back_pressure:
                    predicted_posture = 6  # ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¼­ê¸°
                else:
                    predicted_posture = 4  # ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°
                confidence = min(0.9, (right_pressure / left_pressure - 1) * 0.5 + 0.6)
                
            elif front_pressure > back_pressure * 1.3:
                # ì•ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨
                if np.max(fsr_data[:3]) > np.mean(fsr_data) * 1.5:
                    predicted_posture = 2  # ëª© ìˆ™ì´ê¸°
                elif np.mean(fsr_data[:5]) > np.mean(fsr_data[5:]) * 1.2:
                    predicted_posture = 1  # ê±°ë¶ëª© ìì„¸
                else:
                    predicted_posture = 3  # ì•ìœ¼ë¡œ ë‹¹ê²¨ ê¸°ëŒ€ê¸°
                confidence = min(0.9, (front_pressure / back_pressure - 1) * 0.5 + 0.6)
                
            else:
                # ê· í˜•ì¡íŒ ìì„¸
                predicted_posture = 0  # ë°”ë¥¸ ìì„¸
                balance_score = 1 - abs(left_pressure - right_pressure) / total_pressure
                confidence = min(0.95, balance_score + 0.3)
            
            # ì‹ ë¢°ë„ ë²”ìœ„ ì¡°ì •
            confidence = max(0.3, min(0.95, confidence))
            
            return predicted_posture, confidence
            
        except Exception as e:
            logger.error(f"íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return 0, 0.5
    
    def predict_posture(self, fsr_data: List[float], imu_data: Any = None, 
                       client_id: str = None, device_id: str = None) -> Tuple[int, float]:
        """ì•™ìƒë¸” ê¸°ë°˜ ìì„¸ ì˜ˆì¸¡ ìˆ˜í–‰"""
        start_time = datetime.now()
        
        try:
            # ë°ì´í„° ì „ì²˜ë¦¬
            features = self.preprocess_data(fsr_data)
            
            # 1ì°¨ ë¶„ë¥˜: FSR ê¸°ë°˜ ì˜ˆì¸¡
            if len(self.models) > 1 and "rule_based" not in self.models:
                predicted_posture, confidence, prediction_details = self.ensemble_predict(features)
                method = "ensemble_stage1"
            else:
                # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ ìˆ˜í–‰
                predicted_posture, confidence = self.analyze_fsr_pattern(features)
                prediction_details = {
                    "rule_based": {"prediction": predicted_posture, "confidence": confidence}
                }
                method = "rule_based_stage1"
            
            logger.info(f"ğŸ¥‡ 1ì°¨ ë¶„ë¥˜ ê²°ê³¼: ìì„¸ {predicted_posture} (ì‹ ë¢°ë„: {confidence:.3f})")
            
            # 2ì°¨ ë¶„ë¥˜: 1ì°¨ì—ì„œ ìì„¸ 0(ì •ìì„¸) ë˜ëŠ” 1ë²ˆ ìì„¸ì¸ ê²½ìš° IMU ê¸°ë°˜ ì„¸ë¶€ ë¶„ë¥˜
            if predicted_posture in [0, 1] and imu_data and self.models_stage2:
                logger.info(f"ğŸ¯ ìì„¸ {predicted_posture} ê°ì§€ - 2ì°¨ IMU ë¶„ë¥˜ ì‹œì‘")
                
                # IMU ë°ì´í„° ì „ì²˜ë¦¬
                imu_features = self.preprocess_imu_data(imu_data)
                
                # 2ì°¨ ë¶„ë¥˜ ìˆ˜í–‰
                stage2_prediction, stage2_confidence, stage2_details = self.stage2_predict(imu_features)
                
                # 2ì°¨ ë¶„ë¥˜ ê²°ê³¼ê°€ ìœ ì˜ë¯¸í•œ ê²½ìš° (ìì„¸ 0ì´ ì•„ë‹Œ ê²½ìš°) ê²°ê³¼ ì—…ë°ì´íŠ¸
                if stage2_prediction != 0 and stage2_confidence > 0.6:
                    logger.info(f"ğŸ¯ 2ì°¨ ë¶„ë¥˜ë¡œ ìì„¸ ë³€ê²½: {predicted_posture} -> {stage2_prediction}")
                    predicted_posture = stage2_prediction
                    confidence = stage2_confidence
                    prediction_details.update(stage2_details)
                    method = method + "_+_stage2"
                else:
                    logger.info(f"ğŸ¯ 2ì°¨ ë¶„ë¥˜ ê²°ê³¼ ë¬´ì‹œ: ìì„¸ {stage2_prediction} (ì‹ ë¢°ë„: {stage2_confidence:.3f})")
                    prediction_details.update(stage2_details)
            elif predicted_posture in [0, 1] and not imu_data:
                logger.debug(f"ìì„¸ {predicted_posture}ì´ì§€ë§Œ IMU ë°ì´í„°ê°€ ì—†ì–´ì„œ 2ì°¨ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            elif predicted_posture in [0, 1] and not self.models_stage2:
                logger.debug(f"ìì„¸ {predicted_posture}ì´ì§€ë§Œ 2ì°¨ ëª¨ë¸ì´ ì—†ì–´ì„œ 2ì°¨ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            else:
                logger.debug(f"1ì°¨ ë¶„ë¥˜ ê²°ê³¼ê°€ ìì„¸ {predicted_posture}ì´ë¯€ë¡œ 2ì°¨ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            
            # ìœ íš¨í•œ ìì„¸ ë²”ìœ„ í™•ì¸
            if predicted_posture not in self.posture_labels:
                logger.warning(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ìì„¸ ë²ˆí˜¸: {predicted_posture}")
                predicted_posture = 0  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì •ìì„¸ ì„¤ì •
                confidence = 0.5  # ì¤‘ê°„ ì‹ ë¢°ë„ ì„¤ì •
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # ìƒì„¸ ì˜ˆì¸¡ ê³¼ì • ë¡œê·¸ ì¶œë ¥
            from logger_config import log_prediction_detailed
            log_prediction_detailed(client_id, device_id, fsr_data, prediction_details, processing_time)
            
            # ì˜ˆì¸¡ ë¡œê·¸ ì €ì¥ (ë¹„ë™ê¸°ì ìœ¼ë¡œ)
            self.log_prediction(
                client_id=client_id,
                device_id=device_id,
                fsr_data=fsr_data,
                imu_data=imu_data,
                features=features,
                prediction_details=prediction_details,
                final_prediction=predicted_posture,
                final_confidence=confidence,
                method=method,
                processing_time=processing_time
            )
            
            return predicted_posture, confidence
            
        except Exception as e:
            logger.error(f"ìì„¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëœë¤ ì˜ˆì¸¡ (ë°ëª¨ ëª©ì )
            predicted_posture = random.randint(0, 7)
            confidence = random.uniform(0.4, 0.8)
            logger.info(f"ì˜¤ë¥˜ë¡œ ì¸í•œ ëœë¤ ì˜ˆì¸¡ - ìì„¸: {predicted_posture}, ì‹ ë¢°ë„: {confidence:.3f}")
            return predicted_posture, confidence

    def ensemble_predict(self, features: np.ndarray) -> Tuple[int, float, Dict]:
        """ì•™ìƒë¸” ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡"""
        if self.scaler is not None:
            # ë°ì´í„° ì •ê·œí™” (FSR 11ê°œ íŠ¹ì„±)
            features_scaled = self.scaler.transform(features.reshape(1, -1))
        else:
            features_scaled = features.reshape(1, -1)
            logger.warning("ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ì–´ì„œ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        predictions = {}
        confidences = {}
        voting_scores = np.zeros(len(self.posture_labels))  # ì‹¤ì œ ìì„¸ ê°œìˆ˜ì— ë§ì¶¤
        
        logger.debug(f"ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œì‘ - ìì„¸ ê°œìˆ˜: {len(self.posture_labels)}")
        
        # ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
        for model_name, model in self.models.items():
            if model_name == "rule_based":
                continue
                
            try:
                # ì˜ˆì¸¡ ìˆ˜í–‰
                pred = model.predict(features_scaled)[0]
                predictions[model_name] = pred
                
                logger.debug(f"{model_name.upper()} ì›ì‹œ ì˜ˆì¸¡: {pred}")
                
                # ì‹ ë¢°ë„ ê³„ì‚° (í™•ë¥  ì˜ˆì¸¡ì´ ê°€ëŠ¥í•œ ê²½ìš°)
                if hasattr(model, 'predict_proba'):
                    proba = model.predict_proba(features_scaled)[0]
                    confidence = np.max(proba)
                    confidences[model_name] = confidence
                    
                    # ê°€ì¤‘ íˆ¬í‘œ (í™•ë¥  ê¸°ë°˜)
                    weight = self.model_weights.get(model_name, 1.0)
                    voting_scores += proba * weight
                    logger.debug(f"{model_name.upper()} í™•ë¥  ê¸°ë°˜ íˆ¬í‘œ - í™•ë¥ : {proba}, ê°€ì¤‘ì¹˜: {weight}")
                else:
                    # ë‹¨ìˆœ íˆ¬í‘œ
                    confidence = 0.7  # ê¸°ë³¸ ì‹ ë¢°ë„
                    confidences[model_name] = confidence
                    weight = self.model_weights.get(model_name, 1.0)
                    if pred < len(voting_scores):  # ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
                        voting_scores[pred] += weight
                        logger.debug(f"{model_name.upper()} ë‹¨ìˆœ íˆ¬í‘œ - ìì„¸ {pred}ì— ê°€ì¤‘ì¹˜ {weight} ì¶”ê°€")
                    else:
                        logger.warning(f"{model_name.upper()} ì˜ˆì¸¡ ìì„¸ {pred}ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨ (ìµœëŒ€: {len(voting_scores)-1})")
                    
                logger.debug(f"{model_name.upper()} ì˜ˆì¸¡: {pred}, ì‹ ë¢°ë„: {confidence:.3f}")
                
            except Exception as e:
                logger.error(f"{model_name.upper()} ëª¨ë¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                continue
        
        if len(predictions) == 0:
            # ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í•œ ê²½ìš° ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´
            logger.warning("ëª¨ë“  ML ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´")
            pred, conf = self.analyze_fsr_pattern(features)
            return pred, conf, {"rule_based_fallback": {"prediction": pred, "confidence": conf}}
        
        # íˆ¬í‘œ ì ìˆ˜ ë””ë²„ê¹…
        logger.debug(f"ìµœì¢… íˆ¬í‘œ ì ìˆ˜: {voting_scores}")
        logger.debug(f"íˆ¬í‘œ ì ìˆ˜ í•©ê³„: {np.sum(voting_scores)}")
        
        # ìµœì¢… ì˜ˆì¸¡ ê²°ì • (ê°€ì¥ ë†’ì€ ì ìˆ˜)
        if np.sum(voting_scores) > 0:
            final_prediction = np.argmax(voting_scores)
            logger.debug(f"íˆ¬í‘œ ê¸°ë°˜ ìµœì¢… ì˜ˆì¸¡: {final_prediction} (ì ìˆ˜: {voting_scores[final_prediction]})")
        else:
            # íˆ¬í‘œ ì ìˆ˜ê°€ ëª¨ë‘ 0ì¸ ê²½ìš° - ê°€ì¥ ë§ì´ ì˜ˆì¸¡ëœ ìì„¸ ì„ íƒ
            from collections import Counter
            if predictions:
                prediction_counts = Counter(predictions.values())
                final_prediction = prediction_counts.most_common(1)[0][0]
                logger.warning(f"íˆ¬í‘œ ì ìˆ˜ê°€ 0ì´ì–´ì„œ ë‹¤ìˆ˜ê²°ë¡œ ì„ íƒ: {final_prediction}")
            else:
                final_prediction = 0
                logger.warning("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ì–´ì„œ ê¸°ë³¸ ìì„¸ 0 ì„ íƒ")
        
        # ì•™ìƒë¸” ì‹ ë¢°ë„ ê³„ì‚° (ì •ê·œí™”ëœ ìµœëŒ€ íˆ¬í‘œ ì ìˆ˜)
        if np.sum(voting_scores) > 0:
            final_confidence = voting_scores[final_prediction] / np.sum(voting_scores)
        else:
            final_confidence = 0.5
        
        # ì‹ ë¢°ë„ ë²”ìœ„ ì¡°ì •
        final_confidence = max(0.3, min(0.95, final_confidence))
        
        logger.debug(f"ìµœì¢… ê²°ì •: ìì„¸ {final_prediction}, ì‹ ë¢°ë„ {final_confidence:.3f}")
        
        prediction_details = {
            'individual_predictions': predictions,
            'individual_confidences': confidences,
            'voting_scores': voting_scores.tolist(),
            'ensemble_prediction': final_prediction,
            'ensemble_confidence': final_confidence
        }
        
        logger.debug(f"ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ - ìµœì¢…: {final_prediction}, ì‹ ë¢°ë„: {final_confidence:.3f}")
        
        return final_prediction, final_confidence, prediction_details

    def stage2_predict(self, imu_features: np.ndarray) -> Tuple[int, float, Dict]:
        """2ì°¨ ë¶„ë¥˜: IMU ë°ì´í„° ê¸°ë°˜ ì•™ìƒë¸” ì˜ˆì¸¡"""
        if not self.models_stage2:
            logger.warning("2ì°¨ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return 0, 0.5, {"error": "no_stage2_models"}
        
        # IMU ë°ì´í„° ì •ê·œí™”
        if self.scaler_stage2 is not None:
            imu_scaled = self.scaler_stage2.transform(imu_features.reshape(1, -1))
        else:
            imu_scaled = imu_features.reshape(1, -1)
            logger.warning("2ì°¨ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ì–´ì„œ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        predictions = {}
        confidences = {}
        voting_scores = np.zeros(len(self.posture_labels))
        
        logger.debug(f"2ì°¨ ì˜ˆì¸¡ ì‹œì‘ - IMU íŠ¹ì„±: {imu_features}")
        
        # ê° 2ì°¨ ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
        for model_name, model in self.models_stage2.items():
            try:
                # ì˜ˆì¸¡ ìˆ˜í–‰
                pred = model.predict(imu_scaled)[0]
                predictions[model_name] = pred
                
                logger.debug(f"{model_name.upper()} 2ì°¨ ì˜ˆì¸¡: {pred}")
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                if hasattr(model, 'predict_proba'):
                    proba = model.predict_proba(imu_scaled)[0]
                    confidence = np.max(proba)
                    confidences[model_name] = confidence
                    
                    # ê°€ì¤‘ íˆ¬í‘œ (í™•ë¥  ê¸°ë°˜)
                    weight = self.model_weights.get(model_name, 1.0)
                    voting_scores += proba * weight
                    logger.debug(f"{model_name.upper()} 2ì°¨ í™•ë¥  íˆ¬í‘œ - í™•ë¥ : {proba}, ê°€ì¤‘ì¹˜: {weight}")
                else:
                    # ë‹¨ìˆœ íˆ¬í‘œ
                    confidence = 0.7
                    confidences[model_name] = confidence
                    weight = self.model_weights.get(model_name, 1.0)
                    if pred < len(voting_scores):
                        voting_scores[pred] += weight
                        logger.debug(f"{model_name.upper()} 2ì°¨ ë‹¨ìˆœ íˆ¬í‘œ - ìì„¸ {pred}ì— ê°€ì¤‘ì¹˜ {weight} ì¶”ê°€")
                
            except Exception as e:
                logger.error(f"{model_name.upper()} 2ì°¨ ëª¨ë¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                continue
        
        if len(predictions) == 0:
            logger.warning("ëª¨ë“  2ì°¨ ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨")
            return 0, 0.5, {"error": "all_stage2_models_failed"}
        
        # 2ì°¨ ë¶„ë¥˜ ìµœì¢… ì˜ˆì¸¡ ê²°ì •
        logger.debug(f"2ì°¨ íˆ¬í‘œ ì ìˆ˜: {voting_scores}")
        
        if np.sum(voting_scores) > 0:
            final_prediction = np.argmax(voting_scores)
            final_confidence = voting_scores[final_prediction] / np.sum(voting_scores)
        else:
            # ë‹¤ìˆ˜ê²°ë¡œ ì„ íƒ
            from collections import Counter
            prediction_counts = Counter(predictions.values())
            final_prediction = prediction_counts.most_common(1)[0][0]
            final_confidence = 0.6
        
        # ì‹ ë¢°ë„ ë²”ìœ„ ì¡°ì •
        final_confidence = max(0.3, min(0.95, final_confidence))
        
        prediction_details = {
            'stage2_individual_predictions': predictions,
            'stage2_individual_confidences': confidences,
            'stage2_voting_scores': voting_scores.tolist(),
            'stage2_final_prediction': final_prediction,
            'stage2_final_confidence': final_confidence
        }
        
        logger.info(f"ğŸ¯ 2ì°¨ ë¶„ë¥˜ ì™„ë£Œ: ìì„¸ {final_prediction} (ì‹ ë¢°ë„: {final_confidence:.3f})")
        
        return final_prediction, final_confidence, prediction_details
    
    def get_posture_label(self, posture_id: int) -> str:
        """ìì„¸ IDì— í•´ë‹¹í•˜ëŠ” ë¼ë²¨ ë°˜í™˜"""
        return self.posture_labels.get(posture_id, "ì•Œ ìˆ˜ ì—†ëŠ” ìì„¸")
    
    def log_prediction(self, client_id: Optional[str], device_id: Optional[str], 
                      fsr_data: List[float], imu_data: Any, features: np.ndarray,
                      prediction_details: Dict, final_prediction: int, final_confidence: float,
                      method: str, processing_time: float):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DBì— ë¡œê·¸ë¡œ ì €ì¥"""
        try:
            import json
            
            # ë°ì´í„° ì§ë ¬í™”
            fsr_json = json.dumps(fsr_data)
            imu_json = json.dumps(imu_data) if imu_data else None
            features_json = json.dumps(features.tolist())
            details_json = json.dumps(prediction_details, default=str)
            models_used = list(self.models.keys())
            models_json = json.dumps(models_used)
            
            # ê°œë³„ ëª¨ë¸ ê²°ê³¼ ì¶”ì¶œ
            individual_preds = prediction_details.get('individual_predictions', {})
            individual_confs = prediction_details.get('individual_confidences', {})
            voting_scores = prediction_details.get('voting_scores', [])
            voting_json = json.dumps(voting_scores) if voting_scores else None
            
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO prediction_logs (
                        client_id, device_id, fsr_data, imu_data, raw_fsr_values, preprocessed_data,
                        lr_prediction, lr_confidence, rf_prediction, rf_confidence,
                        dt_prediction, dt_confidence, kn_prediction, kn_confidence,
                        ensemble_prediction, ensemble_confidence, voting_scores,
                        models_used, prediction_method, processing_time_ms
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    client_id, device_id, fsr_json, imu_json, fsr_json, features_json,
                    individual_preds.get('lr'), individual_confs.get('lr'),
                    individual_preds.get('rf'), individual_confs.get('rf'),
                    individual_preds.get('dt'), individual_confs.get('dt'),
                    individual_preds.get('kn'), individual_confs.get('kn'),
                    final_prediction, final_confidence, voting_json,
                    models_json, method, processing_time
                ))
                conn.commit()
                
                # DB ì €ì¥ ì„±ê³µ ë¡œê·¸
                from logger_config import log_db_save
                log_db_save("prediction_logs", True)
                
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ë¡œê·¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            from logger_config import log_db_save
            log_db_save("prediction_logs", False, str(e))

    def get_prediction_statistics(self, hours: int = 24) -> Dict:
        """ìµœê·¼ ì˜ˆì¸¡ í†µê³„ ì¡°íšŒ"""
        try:
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                
                # ìµœê·¼ ì˜ˆì¸¡ í†µê³„
                cursor.execute('''
                    SELECT 
                        prediction_method,
                        COUNT(*) as count,
                        AVG(ensemble_confidence) as avg_confidence,
                        AVG(processing_time_ms) as avg_processing_time
                    FROM prediction_logs 
                    WHERE timestamp >= datetime('now', '-{} hours')
                    GROUP BY prediction_method
                '''.format(hours))
                
                stats = {}
                for row in cursor.fetchall():
                    method, count, avg_conf, avg_time = row
                    stats[method] = {
                        'predictions_count': count,
                        'average_confidence': round(avg_conf or 0, 3),
                        'average_processing_time_ms': round(avg_time or 0, 2)
                    }
                
                # ëª¨ë¸ë³„ ì •í™•ë„ (ê°œë³„ ëª¨ë¸ ê²°ê³¼)
                cursor.execute('''
                    SELECT 
                        COUNT(CASE WHEN lr_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as lr_agreement,
                        COUNT(CASE WHEN rf_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as rf_agreement,
                        COUNT(CASE WHEN dt_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as dt_agreement,
                        COUNT(CASE WHEN kn_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as kn_agreement
                    FROM prediction_logs 
                    WHERE timestamp >= datetime('now', '-{} hours')
                    AND prediction_method = 'ensemble'
                '''.format(hours))
                
                agreement_row = cursor.fetchone()
                if agreement_row:
                    stats['model_agreement'] = {
                        'lr_agreement_pct': round(agreement_row[0] or 0, 1),
                        'rf_agreement_pct': round(agreement_row[1] or 0, 1),
                        'dt_agreement_pct': round(agreement_row[2] or 0, 1),
                        'kn_agreement_pct': round(agreement_row[3] or 0, 1)
                    }
                
                return stats
                
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}

    def validate_model_input(self, fsr_data: List[float]) -> bool:
        """ëª¨ë¸ ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            if not isinstance(fsr_data, list):
                return False
            
            if len(fsr_data) == 0:
                return False
            
            # ëª¨ë“  ê°’ì´ ìˆ«ìì¸ì§€ í™•ì¸
            for value in fsr_data:
                if not isinstance(value, (int, float)):
                    return False
                
                # ìŒìˆ˜ ê°’ í™•ì¸ (ì••ë ¥ ì„¼ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìŒìˆ˜ê°€ ì•„ë‹˜)
                if value < 0:
                    logger.warning(f"ìŒìˆ˜ FSR ê°’ ê°ì§€: {value}")
            
            return True
            
        except Exception as e:
            logger.error(f"ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì˜¤ë¥˜: {e}")
            return False

# PosturePredictor í´ë˜ìŠ¤ëŠ” ì´ì œ EnsemblePosturePredictorë¡œ ëŒ€ì²´ë¨
PosturePredictor = EnsemblePosturePredictor

# ì „ì—­ ì˜ˆì¸¡ê¸° ì¸ìŠ¤í„´ìŠ¤
predictor = EnsemblePosturePredictor()