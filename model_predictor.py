import numpy as np
import logging
from typing import List, Tuple, Dict, Any, Optional
import os
import random
import joblib
from datetime import datetime
from config import config
from database import DatabaseManager

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class EnsemblePosturePredictor:
    def __init__(self, model_path=None):
        self.model_path = model_path or config.MODEL_PATH
        self.models = {}
        self.scaler = None
        self.posture_labels = {
            0: "ë°”ë¥¸ ìì„¸",
            1: "ê±°ë¶ëª© ìì„¸",
            2: "ëª© ìˆ™ì´ê¸°", 
            3: "ì•ìœ¼ë¡œ ë‹¹ê²¨ ê¸°ëŒ€ê¸°",
            4: "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°",
            5: "ì™¼ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°",
            6: "ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¼¬ê¸°",
            7: "ì™¼ìª½ ë‹¤ë¦¬ ê¼¬ê¸°"
        }
        self.supports_proba = True
        self.db_manager = DatabaseManager()
        self.load_ensemble_models()
        
        # ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ (ì„±ëŠ¥ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
        self.model_weights = {
            'lr': 0.3,    # Logistic Regression
            'rf': 0.35,   # Random Forest (ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì¢‹ìŒ)
            'dt': 0.2,    # Decision Tree
            'kn': 0.15    # K-Nearest Neighbors
        }
        
        # ì˜ˆì¸¡ ë¡œê·¸ë¥¼ ìœ„í•œ DB í…Œì´ë¸” ìƒì„±
        self.create_prediction_log_table()
    
    def create_prediction_log_table(self):
        """ì˜ˆì¸¡ ë¡œê·¸ë¥¼ ì €ì¥í•  í…Œì´ë¸” ìƒì„±"""
        try:
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS prediction_logs (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                        client_id TEXT,
                        device_id TEXT,
                        fsr_data TEXT NOT NULL,
                        imu_data TEXT,
                        raw_fsr_values TEXT,
                        preprocessed_data TEXT,
                        
                        -- ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼
                        lr_prediction INTEGER,
                        lr_confidence REAL,
                        rf_prediction INTEGER,
                        rf_confidence REAL,
                        dt_prediction INTEGER,
                        dt_confidence REAL,
                        kn_prediction INTEGER,
                        kn_confidence REAL,
                        
                        -- ì•™ìƒë¸” ê²°ê³¼
                        ensemble_prediction INTEGER NOT NULL,
                        ensemble_confidence REAL NOT NULL,
                        voting_scores TEXT,
                        
                        -- ë©”íƒ€ ì •ë³´
                        models_used TEXT,
                        prediction_method TEXT DEFAULT 'ensemble',
                        processing_time_ms REAL
                    )
                ''')
                conn.commit()
                logger.info("ì˜ˆì¸¡ ë¡œê·¸ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ë¡œê·¸ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    def load_ensemble_models(self):
        """ì—¬ëŸ¬ ML ëª¨ë¸ë“¤ì„ ë¡œë“œí•˜ì—¬ ì•™ìƒë¸” êµ¬ì„±"""
        ml_dir = os.path.join(os.path.dirname(__file__), 'ML')
        model_files = {
            'lr': 'model_lr.joblib',
            'rf': 'model_rf.joblib', 
            'dt': 'model_dt.joblib',
            'kn': 'model_kn.joblib'
        }
        
        scaler_path = os.path.join(ml_dir, 'scaler.joblib')
        
        logger.info("ì•™ìƒë¸” ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        try:
            if os.path.exists(scaler_path):
                self.scaler = joblib.load(scaler_path)
                logger.info("âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # ê° ëª¨ë¸ ë¡œë“œ
        loaded_models = 0
        for model_name, model_file in model_files.items():
            model_path = os.path.join(ml_dir, model_file)
            try:
                if os.path.exists(model_path):
                    model = joblib.load(model_path)
                    self.models[model_name] = model
                    loaded_models += 1
                    logger.info(f"âœ… {model_name.upper()} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.warning(f"âš ï¸ {model_name.upper()} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            except Exception as e:
                logger.error(f"âŒ {model_name.upper()} ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        if loaded_models == 0:
            logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ML ëª¨ë¸ì´ ì—†ì–´ ê·œì¹™ ê¸°ë°˜ ëª¨ë¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            self.create_simple_rule_based_model()
        else:
            logger.info(f"ğŸ¯ ì•™ìƒë¸” êµ¬ì„± ì™„ë£Œ: {loaded_models}ê°œ ëª¨ë¸ ë¡œë“œë¨")
            
        return loaded_models > 0

    def create_simple_rule_based_model(self):
        """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ëª¨ë¸ ìƒì„± (ML ëª¨ë¸ ë¡œë“œê°€ ì‹¤íŒ¨í•  ê²½ìš° ì‚¬ìš©)"""
        logger.info("ê·œì¹™ ê¸°ë°˜ ìì„¸ ë¶„ë¥˜ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤")
        
        # FSR íŒ¨í„´ ê¸°ë°˜ ë¶„ë¥˜ ê·œì¹™
        self.classification_rules = {
            # ê° ìì„¸ë³„ FSR ì„¼ì„œ íŒ¨í„´ íŠ¹ì§•
            0: {'name': 'ë°”ë¥¸ ìì„¸', 'pattern': 'balanced'},
            1: {'name': 'ê±°ë¶ëª© ìì„¸', 'pattern': 'neck_forward'},
            2: {'name': 'ëª© ìˆ™ì´ê¸°', 'pattern': 'head_down'},
            3: {'name': 'ì•ìœ¼ë¡œ ë‹¹ê²¨ ê¸°ëŒ€ê¸°', 'pattern': 'front_heavy'},
            4: {'name': 'ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°', 'pattern': 'right_lean'},
            5: {'name': 'ì™¼ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°', 'pattern': 'left_lean'},
            6: {'name': 'ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¼¬ê¸°', 'pattern': 'right_leg_cross'},
            7: {'name': 'ì™¼ìª½ ë‹¤ë¦¬ ê¼¬ê¸°', 'pattern': 'left_leg_cross'}
        }
        
        self.models = {"rule_based": "rule_based"}
        logger.info("ê·œì¹™ ê¸°ë°˜ ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    
    def preprocess_data(self, fsr_data: List[float], imu_data: Any = None) -> np.ndarray:
        """ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            # FSR ë°ì´í„° ê²€ì¦
            if not isinstance(fsr_data, list):
                raise ValueError("FSR ë°ì´í„°ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤")
            
            # FSR ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            fsr_array = np.array(fsr_data, dtype=float)
            
            # ë°ì´í„° í¬ê¸° í™•ì¸ (11ê°œ ì„¼ì„œ ì˜ˆìƒ)
            expected_fsr_size = 11
            if len(fsr_array) != expected_fsr_size:
                logger.warning(f"ì˜ˆìƒ FSR ì„¼ì„œ ê°œìˆ˜ì™€ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: {expected_fsr_size}, ì‹¤ì œ: {len(fsr_array)}")
                # ë¶€ì¡±í•œ ê²½ìš° 0ìœ¼ë¡œ íŒ¨ë”©, ë§ì€ ê²½ìš° ìë¥´ê¸°
                if len(fsr_array) < expected_fsr_size:
                    fsr_array = np.pad(fsr_array, (0, expected_fsr_size - len(fsr_array)), mode='constant')
                else:
                    fsr_array = fsr_array[:expected_fsr_size]
            
            # í˜„ì¬ëŠ” FSR ë°ì´í„°ë§Œ ì‚¬ìš© (IMU ë°ì´í„°ëŠ” í–¥í›„ í™•ì¥ ê°€ëŠ¥)
            features = fsr_array
            
            logger.debug(f"ì „ì²˜ë¦¬ëœ íŠ¹ì„± ë°ì´í„° í˜•íƒœ: {features.shape}")
            return features
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            raise
    
    def analyze_fsr_pattern(self, fsr_data: np.ndarray) -> Tuple[int, float]:
        """FSR ë°ì´í„° íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ìì„¸ ë¶„ë¥˜"""
        try:
            # ì „ì²´ ì••ë ¥ í•©ê³„
            total_pressure = np.sum(fsr_data)
            
            if total_pressure == 0:
                return 0, 0.5  # ì••ë ¥ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ìì„¸
            
            # ê° ì„¼ì„œë³„ ë¹„ìœ¨ ê³„ì‚°
            ratios = fsr_data / total_pressure
            
            # ì¢Œìš° ê· í˜• ë¶„ì„ (ì„¼ì„œ 1-5: ì™¼ìª½, ì„¼ì„œ 6-11: ì˜¤ë¥¸ìª½ ê°€ì •)
            left_pressure = np.sum(fsr_data[:5])
            right_pressure = np.sum(fsr_data[5:])
            
            # ì•ë’¤ ê· í˜• ë¶„ì„ (ì„¼ì„œ ë°°ì¹˜ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            front_pressure = np.sum(fsr_data[[0, 1, 5, 6]])  # ì•ìª½ ì„¼ì„œë“¤
            back_pressure = np.sum(fsr_data[[3, 4, 8, 9]])   # ë’¤ìª½ ì„¼ì„œë“¤
            
            # ë¶„ë¥˜ ë¡œì§ (ìƒˆë¡œìš´ ìì„¸ ë¶„ë¥˜ì— ë§ê²Œ ì¡°ì •)
            if left_pressure > right_pressure * 1.5:
                # ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨
                if front_pressure > back_pressure:
                    predicted_posture = 7  # ì™¼ìª½ ë‹¤ë¦¬ ê¼­ê¸°
                else:
                    predicted_posture = 5  # ì™¼ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°
                confidence = min(0.9, (left_pressure / right_pressure - 1) * 0.5 + 0.6)
                
            elif right_pressure > left_pressure * 1.5:
                # ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨
                if front_pressure > back_pressure:
                    predicted_posture = 6  # ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¼­ê¸°
                else:
                    predicted_posture = 4  # ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸°ëŒ€ê¸°
                confidence = min(0.9, (right_pressure / left_pressure - 1) * 0.5 + 0.6)
                
            elif front_pressure > back_pressure * 1.3:
                # ì•ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨
                if np.max(fsr_data[:3]) > np.mean(fsr_data) * 1.5:
                    predicted_posture = 2  # ëª© ìˆ™ì´ê¸°
                elif np.mean(fsr_data[:5]) > np.mean(fsr_data[5:]) * 1.2:
                    predicted_posture = 1  # ê±°ë¶ëª© ìì„¸
                else:
                    predicted_posture = 3  # ì•ìœ¼ë¡œ ë‹¹ê²¨ ê¸°ëŒ€ê¸°
                confidence = min(0.9, (front_pressure / back_pressure - 1) * 0.5 + 0.6)
                
            else:
                # ê· í˜•ì¡íŒ ìì„¸
                predicted_posture = 0  # ë°”ë¥¸ ìì„¸
                balance_score = 1 - abs(left_pressure - right_pressure) / total_pressure
                confidence = min(0.95, balance_score + 0.3)
            
            # ì‹ ë¢°ë„ ë²”ìœ„ ì¡°ì •
            confidence = max(0.3, min(0.95, confidence))
            
            return predicted_posture, confidence
            
        except Exception as e:
            logger.error(f"íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return 0, 0.5
    
    def predict_posture(self, fsr_data: List[float], imu_data: Any = None, 
                       client_id: str = None, device_id: str = None) -> Tuple[int, float]:
        """ì•™ìƒë¸” ê¸°ë°˜ ìì„¸ ì˜ˆì¸¡ ìˆ˜í–‰"""
        start_time = datetime.now()
        
        try:
            # ë°ì´í„° ì „ì²˜ë¦¬
            features = self.preprocess_data(fsr_data, imu_data)
            
            # ML ëª¨ë¸ì´ ìˆìœ¼ë©´ ì•™ìƒë¸” ì˜ˆì¸¡, ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜
            if len(self.models) > 1 and "rule_based" not in self.models:
                predicted_posture, confidence, prediction_details = self.ensemble_predict(features)
                method = "ensemble"
            else:
                # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ ìˆ˜í–‰
                predicted_posture, confidence = self.analyze_fsr_pattern(features)
                prediction_details = {
                    "rule_based": {"prediction": predicted_posture, "confidence": confidence}
                }
                method = "rule_based"
            
            # ìœ íš¨í•œ ìì„¸ ë²”ìœ„ í™•ì¸
            if predicted_posture not in self.posture_labels:
                logger.warning(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ìì„¸ ë²ˆí˜¸: {predicted_posture}")
                predicted_posture = 0  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì •ìì„¸ ì„¤ì •
                confidence = 0.5  # ì¤‘ê°„ ì‹ ë¢°ë„ ì„¤ì •
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # ì˜ˆì¸¡ ë¡œê·¸ ì €ì¥ (ë¹„ë™ê¸°ì ìœ¼ë¡œ)
            self.log_prediction(
                client_id=client_id,
                device_id=device_id,
                fsr_data=fsr_data,
                imu_data=imu_data,
                features=features,
                prediction_details=prediction_details,
                final_prediction=predicted_posture,
                final_confidence=confidence,
                method=method,
                processing_time=processing_time
            )
            
            logger.info(f"ìì„¸ ì˜ˆì¸¡ ì™„ë£Œ - ìì„¸: {predicted_posture} ({self.posture_labels[predicted_posture]}), "
                       f"ì‹ ë¢°ë„: {confidence:.3f}, ë°©ë²•: {method}, ì²˜ë¦¬ì‹œê°„: {processing_time:.1f}ms")
            
            return predicted_posture, confidence
            
        except Exception as e:
            logger.error(f"ìì„¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëœë¤ ì˜ˆì¸¡ (ë°ëª¨ ëª©ì )
            predicted_posture = random.randint(0, 7)
            confidence = random.uniform(0.4, 0.8)
            logger.info(f"ì˜¤ë¥˜ë¡œ ì¸í•œ ëœë¤ ì˜ˆì¸¡ - ìì„¸: {predicted_posture}, ì‹ ë¢°ë„: {confidence:.3f}")
            return predicted_posture, confidence

    def ensemble_predict(self, features: np.ndarray) -> Tuple[int, float, Dict]:
        """ì•™ìƒë¸” ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡"""
        if self.scaler is not None:
            # ë°ì´í„° ì •ê·œí™”
            features_scaled = self.scaler.transform(features.reshape(1, -1))
        else:
            features_scaled = features.reshape(1, -1)
            logger.warning("ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ì–´ì„œ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        predictions = {}
        confidences = {}
        voting_scores = np.zeros(8)  # 8ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ íˆ¬í‘œ
        
        # ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
        for model_name, model in self.models.items():
            if model_name == "rule_based":
                continue
                
            try:
                # ì˜ˆì¸¡ ìˆ˜í–‰
                pred = model.predict(features_scaled)[0]
                predictions[model_name] = pred
                
                # ì‹ ë¢°ë„ ê³„ì‚° (í™•ë¥  ì˜ˆì¸¡ì´ ê°€ëŠ¥í•œ ê²½ìš°)
                if hasattr(model, 'predict_proba'):
                    proba = model.predict_proba(features_scaled)[0]
                    confidence = np.max(proba)
                    confidences[model_name] = confidence
                    
                    # ê°€ì¤‘ íˆ¬í‘œ (í™•ë¥  ê¸°ë°˜)
                    weight = self.model_weights.get(model_name, 1.0)
                    voting_scores += proba * weight
                else:
                    # ë‹¨ìˆœ íˆ¬í‘œ
                    confidence = 0.7  # ê¸°ë³¸ ì‹ ë¢°ë„
                    confidences[model_name] = confidence
                    weight = self.model_weights.get(model_name, 1.0)
                    voting_scores[pred] += weight
                    
                logger.debug(f"{model_name.upper()} ì˜ˆì¸¡: {pred}, ì‹ ë¢°ë„: {confidence:.3f}")
                
            except Exception as e:
                logger.error(f"{model_name.upper()} ëª¨ë¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                continue
        
        if len(predictions) == 0:
            # ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í•œ ê²½ìš° ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´
            logger.warning("ëª¨ë“  ML ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´")
            pred, conf = self.analyze_fsr_pattern(features)
            return pred, conf, {"rule_based_fallback": {"prediction": pred, "confidence": conf}}
        
        # ìµœì¢… ì˜ˆì¸¡ ê²°ì • (ê°€ì¥ ë†’ì€ ì ìˆ˜)
        final_prediction = np.argmax(voting_scores)
        
        # ì•™ìƒë¸” ì‹ ë¢°ë„ ê³„ì‚° (ì •ê·œí™”ëœ ìµœëŒ€ íˆ¬í‘œ ì ìˆ˜)
        if np.sum(voting_scores) > 0:
            final_confidence = voting_scores[final_prediction] / np.sum(voting_scores)
        else:
            final_confidence = 0.5
        
        # ì‹ ë¢°ë„ ë²”ìœ„ ì¡°ì •
        final_confidence = max(0.3, min(0.95, final_confidence))
        
        prediction_details = {
            'individual_predictions': predictions,
            'individual_confidences': confidences,
            'voting_scores': voting_scores.tolist(),
            'ensemble_prediction': final_prediction,
            'ensemble_confidence': final_confidence
        }
        
        logger.debug(f"ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ - ìµœì¢…: {final_prediction}, ì‹ ë¢°ë„: {final_confidence:.3f}")
        
        return final_prediction, final_confidence, prediction_details
    
    def get_posture_label(self, posture_id: int) -> str:
        """ìì„¸ IDì— í•´ë‹¹í•˜ëŠ” ë¼ë²¨ ë°˜í™˜"""
        return self.posture_labels.get(posture_id, "ì•Œ ìˆ˜ ì—†ëŠ” ìì„¸")
    
    def log_prediction(self, client_id: Optional[str], device_id: Optional[str], 
                      fsr_data: List[float], imu_data: Any, features: np.ndarray,
                      prediction_details: Dict, final_prediction: int, final_confidence: float,
                      method: str, processing_time: float):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DBì— ë¡œê·¸ë¡œ ì €ì¥"""
        try:
            import json
            
            # ë°ì´í„° ì§ë ¬í™”
            fsr_json = json.dumps(fsr_data)
            imu_json = json.dumps(imu_data) if imu_data else None
            features_json = json.dumps(features.tolist())
            details_json = json.dumps(prediction_details, default=str)
            models_used = list(self.models.keys())
            models_json = json.dumps(models_used)
            
            # ê°œë³„ ëª¨ë¸ ê²°ê³¼ ì¶”ì¶œ
            individual_preds = prediction_details.get('individual_predictions', {})
            individual_confs = prediction_details.get('individual_confidences', {})
            voting_scores = prediction_details.get('voting_scores', [])
            voting_json = json.dumps(voting_scores) if voting_scores else None
            
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO prediction_logs (
                        client_id, device_id, fsr_data, imu_data, raw_fsr_values, preprocessed_data,
                        lr_prediction, lr_confidence, rf_prediction, rf_confidence,
                        dt_prediction, dt_confidence, kn_prediction, kn_confidence,
                        ensemble_prediction, ensemble_confidence, voting_scores,
                        models_used, prediction_method, processing_time_ms
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    client_id, device_id, fsr_json, imu_json, fsr_json, features_json,
                    individual_preds.get('lr'), individual_confs.get('lr'),
                    individual_preds.get('rf'), individual_confs.get('rf'),
                    individual_preds.get('dt'), individual_confs.get('dt'),
                    individual_preds.get('kn'), individual_confs.get('kn'),
                    final_prediction, final_confidence, voting_json,
                    models_json, method, processing_time
                ))
                conn.commit()
                
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ë¡œê·¸ ì €ì¥ ì˜¤ë¥˜: {e}")

    def get_prediction_statistics(self, hours: int = 24) -> Dict:
        """ìµœê·¼ ì˜ˆì¸¡ í†µê³„ ì¡°íšŒ"""
        try:
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                
                # ìµœê·¼ ì˜ˆì¸¡ í†µê³„
                cursor.execute('''
                    SELECT 
                        prediction_method,
                        COUNT(*) as count,
                        AVG(ensemble_confidence) as avg_confidence,
                        AVG(processing_time_ms) as avg_processing_time
                    FROM prediction_logs 
                    WHERE timestamp >= datetime('now', '-{} hours')
                    GROUP BY prediction_method
                '''.format(hours))
                
                stats = {}
                for row in cursor.fetchall():
                    method, count, avg_conf, avg_time = row
                    stats[method] = {
                        'predictions_count': count,
                        'average_confidence': round(avg_conf or 0, 3),
                        'average_processing_time_ms': round(avg_time or 0, 2)
                    }
                
                # ëª¨ë¸ë³„ ì •í™•ë„ (ê°œë³„ ëª¨ë¸ ê²°ê³¼)
                cursor.execute('''
                    SELECT 
                        COUNT(CASE WHEN lr_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as lr_agreement,
                        COUNT(CASE WHEN rf_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as rf_agreement,
                        COUNT(CASE WHEN dt_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as dt_agreement,
                        COUNT(CASE WHEN kn_prediction = ensemble_prediction THEN 1 END) * 100.0 / COUNT(*) as kn_agreement
                    FROM prediction_logs 
                    WHERE timestamp >= datetime('now', '-{} hours')
                    AND prediction_method = 'ensemble'
                '''.format(hours))
                
                agreement_row = cursor.fetchone()
                if agreement_row:
                    stats['model_agreement'] = {
                        'lr_agreement_pct': round(agreement_row[0] or 0, 1),
                        'rf_agreement_pct': round(agreement_row[1] or 0, 1),
                        'dt_agreement_pct': round(agreement_row[2] or 0, 1),
                        'kn_agreement_pct': round(agreement_row[3] or 0, 1)
                    }
                
                return stats
                
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}

    def validate_model_input(self, fsr_data: List[float]) -> bool:
        """ëª¨ë¸ ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            if not isinstance(fsr_data, list):
                return False
            
            if len(fsr_data) == 0:
                return False
            
            # ëª¨ë“  ê°’ì´ ìˆ«ìì¸ì§€ í™•ì¸
            for value in fsr_data:
                if not isinstance(value, (int, float)):
                    return False
                
                # ìŒìˆ˜ ê°’ í™•ì¸ (ì••ë ¥ ì„¼ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìŒìˆ˜ê°€ ì•„ë‹˜)
                if value < 0:
                    logger.warning(f"ìŒìˆ˜ FSR ê°’ ê°ì§€: {value}")
            
            return True
            
        except Exception as e:
            logger.error(f"ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì˜¤ë¥˜: {e}")
            return False

# PosturePredictor í´ë˜ìŠ¤ëŠ” ì´ì œ EnsemblePosturePredictorë¡œ ëŒ€ì²´ë¨
PosturePredictor = EnsemblePosturePredictor

# ì „ì—­ ì˜ˆì¸¡ê¸° ì¸ìŠ¤í„´ìŠ¤
predictor = EnsemblePosturePredictor()